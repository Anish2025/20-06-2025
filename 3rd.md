
## ðŸ“š References

1. **MIT OpenCourseWare â€“ Single Variable Calculus**  
   [https://ocw.mit.edu/courses/18-01sc-single-variable-calculus-fall-2010](https://ocw.mit.edu/courses/18-01sc-single-variable-calculus-fall-2010)  
   â†’ Foundation of derivatives, rules, and real-world interpretation.

2. **3Blue1Brown â€“ Essence of Calculus (Video Series)**  
   [https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)  
   â†’ Intuitive and visual understanding of differentiation and gradients.

3. **DeepLearning.ai â€“ Neural Networks and Deep Learning (Coursera)**  
   [https://www.coursera.org/learn/neural-networks-deep-learning](https://www.coursera.org/learn/neural-networks-deep-learning)  
   â†’ Explains how derivatives are used in backpropagation.

4. **Stanford CS231n: Convolutional Neural Networks for Visual Recognition**  
   [https://cs231n.github.io/optimization-1/](https://cs231n.github.io/optimization-1/)  
   â†’ Great breakdown of gradients, Jacobians, chain rule, and softmax.

5. **Michael Nielsen â€“ Neural Networks and Deep Learning (Free Book)**  
   [http://neuralnetworksanddeeplearning.com/](http://neuralnetworksanddeeplearning.com/)  
   â†’ Chapters 2 & 3 deeply explain how calculus powers neural nets.

6. **PyTorch Autograd Documentation**  
   [https://pytorch.org/docs/stable/autograd.html](https://pytorch.org/docs/stable/autograd.html)  
   â†’ Practical example of automatic differentiation in ML libraries.

7. **Wikipedia â€“ Calculus & Differential Calculus**  
   [https://en.wikipedia.org/wiki/Differential_calculus](https://en.wikipedia.org/wiki/Differential_calculus)  
   â†’ General reference for notations and extended rules.

---
